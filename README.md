

# GAI_Project4

This project involves using the forward noise image from DDPM as the input for DIP. You can take a quick look at run_test.ipynb for the result.

The training of the DIP model typically involves inputting a complete Gaussian-distributed noise image. However, I believe that using noise from different time steps of the DDPM forward process as input for DIP might yield better results.

For noise images at different time steps, as long as the time step is not too large, the noise image will retain some features. I hypothesize that this method will help DIP learn more effectively.

The method of generating noise from DDPM is :

![t](https://latex.codecogs.com/svg.image?q(x_t|x_0)=N(x_t;\sqrt{\bar{a}}x_{t-1};(1-a_h)I))

We can implement as:

```py
# get current alpha_bar by current time_step
alpha_bar = torch.tensor([self.alpha_bars[t]])                      
# repeat it B times(for batch calculation)
alpha_bar = repeat(alpha_bar, 'C -> B C', B=B).to(self.device)      

noise = alpha_bar.sqrt().view(B, 1, 1, 1) * x.to(self.device) + (1 - alpha_bar).sqrt().view(B, 1, 1, 1) * eta
```

## Installation
```bash
pip install -r requirements.txt
```

The dataset can be found at https://www.kaggle.com/datasets/kshitij192/cars-image-dataset

I'm using an image shape of (128, 128, 1) as the input because I think my local computer can't handle training a deeper model with more complex images.


## Execution 

```bash
python main.py
```

## Demo

The experimental results show that using noise images generated by the DDPM forward process for training yields better results for darker images and gets higher SSIM evaluation score. The training process also has significantly lower loss, while the time expenditure is approximately the same.

SSIM evaluation (Training 100 epochs) :

| with time step | without time step |
| ---- | ---- |
| 0.999687 | 0.999616 |

Without time step noise :

![gen_noise](https://i.imgur.com/xmb3yaT.png)

With time step noise :

![gen_noise](https://i.imgur.com/Ly4HO5E.png)

## Hyperparameter adjustment

This is the SSIM evaluation of different learning rate : 
| 0.001 | 0.009 | 0.019 |
| ---- | ---- | ---- |
| 0.999783 | 0.999885 | 0.999808 |

Because the images are only 128x128x1 in size, the SSIM values are very close. However, there are still noticeable differences in the generated images.

![lr_image](https://i.imgur.com/fGqJ2ny.png)

From top left to bottom right, the values range from 0.001 to 0.019, with increments of 0.002 for each step.

## Conclusion

I have found that using noise images generated by the forward process in DDPM leads to better learning outcomes for DIP on average. It is speculated that the model can learn image features more effectively from different levels of noise, as the original DIP only uses noise images from a Gaussian distribution as input for the backward process.



