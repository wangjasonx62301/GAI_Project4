

# GAI_Project4

This project involves using the forward noise image from DDPM as the input for DIP.

The training of the DIP model typically involves inputting a complete Gaussian-distributed noise image. However, I believe that using noise from different time steps of the DDPM forward process as input for DIP might yield better results.

For noise images at different time steps, as long as the time step is not too large, the noise image will retain some features. I hypothesize that this method will help DIP learn more effectively.

The experimental results show that using noise images generated by the DDPM forward process for training yields better results for darker images. The training process also has significantly lower loss, while the time expenditure is approximately the same.

The method of generating noise from DDPM is :

![t](https://latex.codecogs.com/svg.image?q(x_t|x_0)=N(x_t;\sqrt{\bar{a}}x_{t-1};(1-a_h)I))

We can implement as:

```py
# get current alpha_bar by current time_step
alpha_bar = torch.tensor([self.alpha_bars[t]])                      
# repeat it B times(for batch calculation)
alpha_bar = repeat(alpha_bar, 'C -> B C', B=B).to(self.device)      

noise = alpha_bar.sqrt().view(B, 1, 1, 1) * x.to(self.device) + (1 - alpha_bar).sqrt().view(B, 1, 1, 1) * eta
```

## Installation
```bash
pip install -r requirements.txt
```

The dataset can be found at https://www.kaggle.com/datasets/kshitij192/cars-image-dataset


## Execution 

```bash
python main.py
```

## Demo

Without time step noise :

![gen_noise](https://i.imgur.com/xmb3yaT.png)

With time step noise :

![gen_noise](https://i.imgur.com/Ly4HO5E.png)

## More

This is the result of different learning rate : 

## Conclusion

I have found that using noise images generated by the forward process in DDPM leads to better learning outcomes for DIP on average. It is speculated that the model can learn image features more effectively from different levels of noise, as the original DIP only uses noise images from a Gaussian distribution as input for the backward process.



